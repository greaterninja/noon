0x01eadd7317cef9adc2a765d2fd140865ede4dcc692affb2ddcfa78aaf02b7a5e: Sync round reset to #2347973
Last imported block: #2350672, 0x0aa8c60e427bb1af933b3c7f2e5a7a577f313e384a4acd74e49223942a08bd15
28 17:40:40 - last call of start_sync_round
0xd1e56a319ebc5c65eccac4fa9f5671ce5537eb649edb8521580a27dcdf99c703: another bad block

How does the sync round normally reset?

Problem: gets stuck in block_sync::request_blocks state = State::Blocks

The original bug was in fact not caused (directly?) via the 'queue full' causing a restart as originally thought. In fact it retracted again, with only a single peer returning no blocks.

So there are two cases causing a retraction: before and after my fix

Ok so with the latest fixes the problem is that we get stuck on some invalid block

Idea: what if we delayed the retraction so that it doesn't shoot back too quickly

Idea: problem caused by async import meaning old block rounds are going too fast

Gets stuck because of blocks_isempty after reset_to

Should find an alternative solution to andres fix - delay somehow

15:46: Running POA locally - find cause of retraction. So I can repro an dcome up with a solution
15:46: Meanwhile, think about the other issue - if it does revert how to avoid getting stuck with old blocks

31/08 16:56: Unknown old block parent - why does it happen only after queue full?

POA repro:

re: queue full + unknown parent: could be because subchain gets fully downloaded but not all inserted, and a following subchain subsequently gets downloaded and can't be inserted because unknown parent

however, another angle is that after initial queue full - it has also reverted to 0 again and now gets to a certain point before it goes back because the blocks are already all in the chain? It seems to be fighting between retracting and going forwards, retracting but moving forwards a few blocks at a time


03/09/18
========

Testing Idle state, considering options for preventing 'missing block parent'. Pausing sync:

test out whether pausing the old block sync here (add Waiting state) will fix issue
						// just need to unpause on check_resume checking whether old block import queue is full
						// if that works I can abstract the queue pausing with NewBlocks

						// alternatively we could do something a bit more sophisticated, and instead of throwing blocks away we could
						// only drain as many as we can handle in the queue to avoid throwing away, and then pausing. However not sure how this would affect other threads - will it still try to download future blocks in the meantime. Could keep them in 'blocks' until queued. Do we need to drain blocks all at once? Or use some kind of 2PC. Need to keep it simple though! Quick fix, then refactor later.

04/09/2018
==========

Pauses, but it stil succumbs to Unknown parent. Local log critical point:

2018-09-04 17:28:03  IO Worker #1 TRACE sync  Starting round (last imported count = Some(10072), last started = 2387129, block = 2397202
2018-09-04 17:28:09  IO Worker #0 TRACE sync  Resetting sync round to: 0xaef5…15dc
2018-09-04 17:28:10  IO Worker #1 TRACE sync  Starting round (last imported count = Some(19918), last started = 2397202, block = 2417121
2018-09-04 17:28:10  IO Worker #2 TRACE sync  Unknown new block parent 0xcff9a5ca80780b19c8c0e873befcf474477261d90c3aeb8f8f3e574362c6d099, h: 0xf43a76551187028569f03be63d66014c299cd457c12913ab6a9be7a98d1e55a5 restarting sync
2018-09-04 17:28:10  IO Worker #2 TRACE sync  Resetting sync round to: 0xaef5…15dc
2018-09-04 17:28:10  IO Worker #0 TRACE sync  Starting round (last imported count = Some(0), last started = 2417121, block = 2417121

The key is in the collect_blocks - need to just figure out how we get into that state. REPRODUCE!

05/09/2018
==========

So it resets and then delayed response from peer with blocks ahead of queue full cut off. Need to prevent those blocks being added.

What if I add those missing heads

Converging on some ideas:

Either chunk drain so that we don't discard blocks when import queue full. Head only advances as far as blocks which are imported. Difference with new blocks queue which accepts all blocks and pauses syncing. Would keep the round going if not emptying the blocks completely. Problem: checking queue size before draining, queue might be populated by another thread. RACE CONDITION. Also code might be a bit tricky.

Or on Waiting we can reset peers while waiting so we don't keep requesting future

ALSO: Check TODO about checking heads on ChainHead are enough apart to avoid 

Multiple rounds with neighbouring chain heads making imported last round = 0 and triggering retraction


